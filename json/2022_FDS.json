[{"question": "What class does the Naive Bayes classifier predict for a given observation?", "answers": ["The class maximizing the joint predictors probability", "The class minimizing the joint predictors probability", "The class maximizing the joint predictors/labels probability", "The class minimizing the joint predictors/labels probability"], "correct": "C"}, {"question": "If your dataset has two variables \ud835\udc99, \ud835\udc99\u2032 such that \ud835\udc99 = \ud835\udc82 \u22c5 \ud835\udc99\u2032 for some constant a > 0, then you have:", "answers": ["overfitting", "underfitting", "multicollinearity", "supercollinearity"], "correct": "C"}, {"question": "A na\u00efve Bayes classifier can deal with previously unseen feature-label combination through:", "answers": ["Laplacian smoothing", "Bootstrapping", "Stratified cross-validation", "Repeated sampling"], "correct": "A"}, {"question": "For a linear regression model, the expected squared error can be decomposed in:", "answers": ["Variance and covariance", "SSE and SST", "Underfit and overfit", "Bias and variance noise"], "correct": "D"}, {"question": " What is the key assumption of the Na\u00efve Bayes Classifier?", "answers": ["The predictors and labels are independent", "Each predictor follows a Gaussian distribution", "The predictors are independent conditionally on the label", "The number of predictors is at most poly(n)"], "correct": "C"}, {"question": "Which one of the following performance indicates the best model for prediction?", "answers": ["\ud835\udc45' = 0.2 on training, \ud835\udc45' = 0.1 on test", "\ud835\udc45' = 0.7 on training, \ud835\udc45' = 0.7 on test", "\ud835\udc45' = 0.8 on training, \ud835\udc45' = 0.1 on test", "\ud835\udc45' = 0.9 on training, \ud835\udc45' = \u22120.9 on test"], "correct": "B"}, {"question": "You want to predict the market price of a team\u2019s merchandising (t-shirts, hats..), according to the team\u2019s seasonal performance. You suggest using:", "answers": ["Linear regression", "Logistic regression", "Linear programming", "Clustering"], "correct": "A"}, {"question": "When is the accuracy a misleading classifier performance measure?", "answers": ["When the population label proportions are unbalanced", "When the population label proportions are balanced", "When the sensitivity is high", "When the specificity is low"], "correct": "A"}, {"question": "The goal of linear regression is to?", "answers": ["Make America great again", "Group similar observations together", "Learn a linear function from data", "Evaluate the amount of noise in the data"], "correct": "C"}, {"question": "In the bias-variance decomposition of the expected squared error, what does high bias suggest?", "answers": ["Noisy data", "Overfitting", "Underfitting", "Crossfitting"], "correct": "C"}, {"question": "Social network users often form communities according to their tastes. If you had access to their personal data, you may verify this intuition by:", "answers": ["Linear Regression", "Logistic Regression", "Clustering", "Linear programming"], "correct": "C"}, {"question": "R2 is a measure of:", "answers": ["Reliability of predictions", "Goodness of fit", "Significance of estimates", "Model complexity"], "correct": "B"}, {"question": "A company wants to relate the monthly revenue to productivity parameters such as total number of working hours, etc. They could use:", "answers": ["Linear regression", "Logistic regression", "Clustering", "Linear programming"], "correct": "A"}, {"question": "How do you perform a linear regression in R?", "answers": ["lm(y ~ x, data)", "lm(y ~ x, data, family = \u201cbinomial\u201d)", "predict(y ~ x, data)", "predict(y ~ x, data, binomial)"], "correct": "A"}, {"question": "Your friend proposes to cluster 300 observations by trying all possible clustering and taking the one that minimizes intra cluster variance. You observe that:", "answers": ["This is the only possible approach", "This does not produce a good clustering", "This does require a few seconds", "This does require a centuries"], "correct": "D"}, {"question": "Single-linkage clustering works by", "answers": ["Repeatedly recomputing the centroids of clusters", "Repeatedly merging smaller clusters into larger ones", "Enumerating all possible clustering of the given points", "Enumerating all possible points in a cluster"], "correct": "B"}, {"question": "In linear regression, a high value of \ud835\udc79\ud835\udfd0 on the training set suggests:", "answers": ["A small error of the model on the fitted data", "A small error of the model on future predictions", "A large error of the model on the fitted data", "A large error of the model on future predictions"], "correct": "A"}, {"question": "A logistic regression gives the following scores, preceded by the actual label: (Y, 0.85), (Y, 0.75), (N,0.6), (Y,0.5), (N, 0.4), (N, 0.2). For a sensitivity of at least 2/3, the best choice is to predict Y when the score is at least:", "answers": ["0.9", "0.75", "0.6", "0.45"], "correct": "B"}, {"question": "Look at the confusion matrix below. What we can say?", "answers": ["The sensitivity is < 0.80%", "There are less positives than negatives", "The accuracy is > 90%", "The classifier predicts 1 on 60% of the times"], "correct": "D"}, {"question": "A set of observations (\ud835\udc99\ud835\udfcf, \ud835\udc9a\ud835\udfcf), (\ud835\udc99\ud835\udfd0,\ud835\udc9a\ud835\udfd0)\u2026(\ud835\udc99\ud835\udc8f, \ud835\udc9a\ud835\udc8f) obeys the law \ud835\udc9a\ud835\udc8a \u2254 \ud835\udc82\ud835\udc99\ud835\udc8a + \ud835\udc83 + \ud835\udf3a\ud835\udc8a, where \ud835\udf3a\ud835\udc8a is some random noise. The task of estimating a and b from the dataset is called:", "answers": ["Logistic regression", "Linear regression", "Linear programming", "Logistic programming"], "correct": "B"}, {"question": "Laplacian smoothing aims at:", "answers": ["Producing readable plots by using an average window", "Reducing the model\u2019s dependence on the noise", "Improving the feature quality by removing outliers", "Avoid penalizing previously unseen observations"], "correct": "D"}, {"question": "A dataset of points (\ud835\udc99\ud835\udfcf, \ud835\udc9a\ud835\udfcf), (\ud835\udc99\ud835\udfd0,\ud835\udc9a\ud835\udfd0)\u2026(\ud835\udc99\ud835\udc8f, \ud835\udc9a\ud835\udc8f) has been generated by the model \ud835\udc9a\ud835\udc8a \u2254 \ud835\udc82\ud835\udc99\ud835\udc8a + \ud835\udc83 + \ud835\udf3a\ud835\udc8a, where \ud835\udf3a\ud835\udc8a is gaussian noise. Linear regression aims at estimating:", "answers": ["a and b", "a and \ud835\udf00", "x and b", "x and y"], "correct": "A"}, {"question": "Which one of the following R commands selects only the rows of data where X equals 0?", "answers": ["select(data, X == 0)", "filter(data, X==0)", "summarize(data, X==0)", "table(data, X == 0)"], "correct": "B"}, {"question": "If an algorithm has exponential complexity, then we can assume that:", "answers": ["In practice it is still fast enough to be useful", "It admits a polynomial-time algorithm", "It can be solved by finding an optimal clustering", "No technological progress will ever make it practical"], "correct": "D"}, {"question": "If you have n points, what is the number of clusters that minimizes the within-cluster sum of square?", "answers": ["1", "k", "n", "We cannot say"], "correct": "C"}, {"question": "Which regression model has smaller squared error in fitting a real function \ud835\udc87(\ud835\udc99)?", "answers": ["A simple linear regression", "A logistic regression", "A polynomial regression of degree 2", "A polynomial regression of degree 10"], "correct": "A"}, {"question": "A doping screening is tested on a pool of 800 athletes of which 796 are clean. The test is correct in 99% of the cases. What can we say about it?", "answers": ["It may have missed all of the doped athletes", "It may have missed all of the clean athletes", "It identified all of the doped athletes", "It identified all of the clean atheletes"], "correct": "A"}, {"question": "In linear programming, the space of feasible solution is:", "answers": ["An arbitrary set", "A subset of \ud835\udc45'", "A convex polytope", "None of the above"], "correct": "C"}, {"question": "The explained variance of a clustering equals:", "answers": ["Within-cluster SSE divided by total sum of squares", "Total sum of squares divided by within-cluster SSE", "Within-cluster SSE divided by between-cluster SSE", "Total sum of squares divided by between-cluster SSE"], "correct": "A"}, {"question": "Gradient descent is a technique we have used to:", "answers": ["Compute the optimal number of clusters", "Reduce the noise in the training set", "Find the local minima of a function", "Estimate the probability of false positive"], "correct": "C"}, {"question": "Which of these models is probably overfitting?", "answers": ["\ud835\udc45' = 0.1 on training, \ud835\udc45' = 0.1 on test", "\ud835\udc45' = 0.8 on training, \ud835\udc45' = 0.7 on test", "\ud835\udc45' = 0.7 on training, \ud835\udc45' = 0.7 on test", "\ud835\udc45' = 0.8 on training, \ud835\udc45' = 0.1 on test"], "correct": "D"}, {"question": "Laplacian smoothing aims at:", "answers": ["Improving the feature quality by removing outliers", "Producing readable plots", "Reducing the model\u2019s dependence on the noise", "Avoid penalizing previously unseen observations"], "correct": "C"}, {"question": "To visualize a hierarchical clustering one can use:", "answers": ["a dendrogram ", "a ROC curve", "a boxplot", "a histogram"], "correct": "A"}, {"question": "The goal of linear regression is to:", "answers": ["bring peace to the world", "group similar observations together", "learn a linear function from data ", "evaluate the amount of noise in the data"], "correct": "C"}, {"question": "Naive Bayes classiers work well for:", "answers": ["linear programming", "spam filtering ", "k-center clustering", "speech recognition"], "correct": "B"}, {"question": "The explained variance of a clustering equals:", "answers": ["(total variance)/(within-cluster variance)", "(within-cluster variance)/(between-cluster variance)", "(between-cluster variance)/(total variance) ", "(within-cluster variance)/(total variance)"], "correct": "C"}, {"question": "A binary classifier on 6 points gives the probabilities: 0.9, 0.85, 0.75, 0.5, 0.4, 0.3; the correct labels are 1,1,0,1,0,0. What is the best probability threshold, if we need FPR <= 1/3?", "answers": ["0.45 ", "1.0", "0.95", "0.25"], "correct": "A"}, {"question": "Mark the wrong statement about gradient descent:", "answers": ["batch gradient descent approximates \u25bdf using a mini-batch", "stochastic gradient descent approximates \u25bdf with a single example", "there is no guarantee to nd the global minimum", "increasing the learning rate damps oscillations "], "correct": "D"}, {"question": "Which task does not require to learn a model?", "answers": ["Clustering ", "Linear Regression", "Classication", "Logistic Regression"], "correct": "A"}, {"question": "For two sets A, B the probability that the first element in a random permutation of A U B is in A \u2229 B:", "answers": ["is J(A,B) / |A \u2229 B|", "is J(A,B) ", "is 1/|A|+1/|B|", "is 1/(|A||B|)"], "correct": "B"}, {"question": "The R2 and the p-values of a regression:", "answers": ["are always equivalent", "cannot be both positive", "measure different aspects ", "are negatively correlated"], "correct": "C"}, {"question": "xXmini=1k||x-ci||22 is the objective function of:", "answers": ["k-squares", "k-medians", "k-centers", "k-means"], "correct": "D"}, {"question": "Classification accuracy is misleading when:", "answers": ["the label proportions are unbalanced ", "the label proportions are balanced", "the dataset is too small", "the dataset is too large"], "correct": "A"}, {"question": "A binary classifier on 6 points gives the probabilities: 0.85, 0.75, 0.65, 0.5, 0.4, 0.2; the correct labels are 1,1,1,0,0,0. What is the best probability threshold?", "answers": ["0.3", "0.6 ", "0.7", "0.9"], "correct": "B"}, {"question": "An algorithm is considered practical if its running time, as a function of the input size, is:", "answers": ["exponential", "polynomial ", "linear", "logarithmic"], "correct": "B"}, {"question": "The naive Bayes classier learns:", "answers": ["the marginal distribution of predictors", "the joint distribution of predictors", "the joint distribution of predictors and labels ", "the marginal distribution of labels"], "correct": "C"}, {"question": "k-PCA differs from k-means in that xi is:", "answers": ["any PCA component", "any linear combination of PCA components ", "orthogonal to all PCA components", "any a convex combination of PCA components"], "correct": "B"}, {"question": "In logistic regression, the estimated probability of xi being a positive is:", "answers": ["1/(1+e-Tx) ", "1/(1+|x|2)", "log(Tx/(1-Tx))", "log(xi)"], "correct": "A"}, {"question": "A sports betting agency wants to predict whether the Italian national football team will or not qualify for the World Cup championship. They should use:", "answers": ["Clustering", "Logistic regression ", "Linear programming", "Linear regression"], "correct": "B"}, {"question": "A problem X  NP is said to be NP-complete if:", "answers": ["X can be reduced to every Y  NP in polytime", "every Y  NP can be reduced to X in polytime", "no Y  NP can be reduced to X in polytime", "none of the others"], "correct": "B"}, {"question": "The quadratic loss of linear regression is:", "answers": ["i=1m(yi-yi)2", "i=1m(xi-xi)2", "i=1m(xi-yi)2", "i=1m(yi2-yi2)2"], "correct": "A"}, {"question": "What is the best threshold value for turning probability scores into binary predictions?", "answers": ["the one that maximizes sensitivity", "it depends on the problem ", "the one that maximizes accuracy", "the one that maximizes specificity"], "correct": "B"}, {"question": "In Human coding, the encoder:", "answers": ["processes whole runs of identical input symbols", "works by solving a clustering problem", "works by solving a regression problem", "processes each input symbol individually "], "correct": "D"}, {"question": "The Maximum Likelihood Estimator for the parameters of a linear model with independent Gaussian noise is:", "answers": ["the OLS solution vector *  ", "the square root of the OLS solution *", "it depends on the dataset", "the vector  of the generating process"], "correct": "A"}, {"question": "Consider the LP: min f(x,y)=x+y; x+y2; x,y0. The corresponding polytope is:", "answers": ["degenerate", "bounded", "unbounded", "empty "], "correct": "D"}, {"question": "Min-hashing maps each document to:", "answers": ["one hash signature ", "a distance matrix", "the set of most frequent terms", "a real vector"], "correct": "A"}, {"question": "How do you do a linear regression in R?", "answers": ["predict(y  x, data)", "lm(y  x, data) ", "predict(y  x, data, family=\"binomial\")", "lm(y  x, data, family=\"binomial\")"], "correct": "B"}, {"question": "How do you measure the significance of an estimate?", "answers": ["with its magnitude", "with R2", "with its p-value", "with its sign"], "correct": "C"}, {"question": "A manufacturing company wants to nd out the relationship between the budget spent in advertising and the total sales of the next semester. They could use:", "answers": ["Linear Regression", "Logistic Regression", "Clustering", "Linear Programming"], "correct": "A"}, {"question": "The company wants to predict if a machine will have a technical failure in the next 10 days. This could be done with:", "answers": ["Linear Regression", "Logistic Regression", "Clustering", "Linear Programming"], "correct": "B"}, {"question": "Moreover, items from the same production line are similar while those from different lines are radically different. You suggest to check by using:", "answers": ["Linear Regression", "Logistic Regression", "Clustering", "Linear Programming"], "correct": "C"}, {"question": "What is the true positive rate aka sensitivity?", "answers": ["the fraction of negatives that are incorrectly classified", "the fraction of negatives that are correctly classified", "the fraction of positives that are incorrectly classified", "the fraction of positives that are correctly classified"], "correct": "D"}, {"question": "Single-linkage clustering works by:", "answers": ["repeatedly recomputing the centroids of clusters", "repeatedly merging smaller clusters into larger ones", "enumerating all possible clustering of the given points", "enumerating all possible points in a cluster"], "correct": "B"}, {"question": "You have a set of observations (x; y) with x; y 2 R. Which one of the following gives the highest R2?", "answers": ["Simple linear regression", "Polynomial regression of degree 2", "Polynomial regression of degree 10", "Logistic regression\t"], "correct": "C"}, {"question": "Which one of the following performances indicates the best model for prediction?", "answers": ["R2 = 0:2 on training, R2 = 0:1 on test", "R2 = 0:7 on training, R2 = 0:7 on test", "R2 = 0:8 on training, R2 = 0:1 on test", "R2 = 0:9 on training, R2 = \udbc0\udc000:9 on test"], "correct": "B"}, {"question": "Which task does not require a training set (i.e. a dataset used for learning a model)?", "answers": ["Linear Regression", "Logistic Regression", "Classification", "Clustering"], "correct": "D"}, {"question": "If you have n points, what is the number of clusters that minimizes the within-cluster sum of squares?", "answers": ["1", "k", "n", "we cannot say"], "correct": "C"}, {"question": "In the bias-variance decomposition of the expected squared error, what does a high bias suggest?", "answers": ["noisy data", "overtting", "undertting", "crosstting"], "correct": "C"}, {"question": "A set of observations (x1; y1), (x2; y2), \u2026,(xn; yn) obeys the law yi := axi + b + i where  i is some random noise. The task of estimating a and b from the dataset is called:", "answers": ["logistic regression", "linear regression", "linear programming", "logistic programming"], "correct": "B"}, {"question": "A regression model (M1) on a training set gives R2 = 0.5 while a second model (M2) gives R2 = 0.9. What can we say about predictions on a test set?", "answers": ["M2 will have error smaller than M1", "M2 will have error larger than M1", "M2 will have the same error as M1", "we cannot say"], "correct": "D"}, {"question": "You developed a clinical test to distinguish sick patients from healthy patients. In the population, on average 998 out of 1000 people are healthy, and the test gives an incorrect prediction in 0.5% of the cases. This means the test:", "answers": ["identifies all the healthy patients", "identifies all the sick patients", "could miss all the healthy patients", "could miss all the sick patients"], "correct": "D"}, {"question": "How would you describe overfitting?", "answers": ["the model is too complex and follows the noise", "the model is too complex and discards the noise", "the model is too simple and follows the noise", "the model is too simple and discards the noise"], "correct": "A"}, {"question": "You have to convert the scores given by a logistic regression model into binary predictions. What is the best threshold?", "answers": ["the one that maximizes accuracy", "the one that maximizes TPR", "the one that maximizes FPR", "it depends on the requirements"], "correct": "D"}, {"question": "Given a linear regression model, the expected squared error can be usefully decomposed in:", "answers": ["SSE and SST", "underfit, overfit and noise", "bias, variance, and error", "variance and covariance"], "correct": "C"}, {"question": "Look at the confusion matrix below (1=positive=true,0=negative=false). What can we say?", "answers": ["the specificity is 2/3", "the sensitivity is 2/3", "the accuracy is 2/3", "none of the above"], "correct": "A"}, {"question": "You are using k-means, and notice that different executions give different results. This happens since:", "answers": ["k-means is randomized", "clustering can take exponential time", "this is unsupervised learning", "you are using the wrong value for k"], "correct": "A"}, {"question": "You have 6 observations; their class (Positive or Negative) and the score given by a logistic regression are as follows: (P,0.9), (P,0.85), (N,0.75), (P,0.5), (N,0.4), (N,0.3). If you do not want the false positive rate of your classier to exceed 1/3, the best choice is to predict \u201cY\" whenever the score is at least:", "answers": ["1.2", "1.0", "0.45", "0.25"], "correct": "C"}, {"question": "Logistic regression finds the parameters that maximize: ", "answers": ["the mean square error of the input data", "the skewness of the input data", "the inter-cluster distance of the input data", "the log-likelihood of the input data"], "correct": "D"}, {"question": "What does the Bayesian Optimal Classier need to know in order to work?", "answers": ["the marginal distribution of each variable", "the marginal distribution of the label", "the joint distribution of variables and label", "the joint distribution of the variables"], "correct": "C"}, {"question": "Which one of the following classifiers has the best performance?", "answers": ["TPR=0.2, FPR=0.2", "TPR=0.2, FPR=0.8", "TPR=0.8, FPR=0.2", "TPR=0.8, FPR=0.8"], "correct": "C"}, {"question": "Your boss calls you to tell your new regression model seems completely useless for prediction, in spite of the high R2 of the t. You realize that probably there is:", "answers": ["underfitting", "overfitting", "correlation", "no tomorrow"], "correct": "B"}, {"question": "From the confusion matrix below, what can we say?", "answers": ["R2 = 0:67", "accuracy = 80%", "all good things must come to an end", "sensitivity < 80%"], "correct": "B"}, {"question": "Consider the LP: max f(x,y)=x+3y; x10; y3. The value of the optimal solution is:", "answers": ["19", "23", "12", "40"], "correct": "A"}, {"question": "Your friend proposes a novel clustering algorithm that tries all possible clusterings of the data. This algorithm:", "answers": ["has exponential complexity", "is efficient but gives poor clusterings", "has polynomial complexity", "is efficient and gives good clusterings"], "correct": "A"}, {"question": "In a binary classier build by thresholding the scores of a logistic regression model, the positive observations:", "answers": ["have a score strictly higher than all the negatives", "have higher density than the negatives", "are at least as many as the negatives", "are separated from the negatives by a hyperplane"], "correct": "D"}, {"question": "The class NP contains all problems whose solution:", "answers": ["can be verified in polytime", "requires exponential time", "none of the others", "can be computed in polytime"], "correct": "A"}, {"question": "Lloyd's algorithm for k-means works by:", "answers": ["evaluating all possible points in a cluster", "evaluating all possible clustering of the points", "repeatedly merging clusters", "repeatedly adjusting the centroids of clusters"], "correct": "D"}, {"question": "You want to learn how your revenue depends on parameters such as number of working hours, etc. You could use:", "answers": ["Linear Regression", "Linear Programming", "Logistic Regression", "Clustering"], "correct": "A"}, {"question": "In least squares, R2 can be seen as:", "answers": ["the norm of the parameter vector", "none of the others", "the gain over a baseline model", "the inverse of the SSE"], "correct": "C"}, {"question": "The ROC curve shows:", "answers": ["specificity versus sensitivity", "specificity versus FPR", "TPR versus sensitivity", "TPR versus FPR"], "correct": "D"}, {"question": "Can feature scaling improve the model fitted via least squares?", "answers": ["yes, in terms of p-values", "no", "yes, in terms of interpretability", "yes, in terms of R2"], "correct": "C"}, {"question": "Can a clustering on n points achieve 0 within-cluster sum of squares?", "answers": ["yes, with 1 cluster", "yes, with k clusters", "yes, with n clusters", "no, never"], "correct": "C"}, {"question": "In linear regression, if the p-value for the estimate i is small enough, then we:", "answers": ["accept the null hypothesis i = 0", "reject the null hypothesis i = 0", "use a model with more features", "use a model with more parameters"], "correct": "B"}, {"question": "Texts written in the same language have a similar letter frequency distribution. You can check this fact by:", "answers": ["Logistic Regression", "Linear Programming", "Linear Regression", "Clustering"], "correct": "D"}, {"question": "Texts written in the same language have a similar letter frequency distribution. You can check this fact by:", "answers": ["Logistic Regression", "Linear Programming", "Linear Regression", "Clustering"], "correct": "D"}, {"question": "Two classifiers, C1 and C2, have accuracy respectively 98\\\\% \\\\and 95%. Which one is the best?", "answers": ["C1", "They are equivalent", "We cannot say", "C2"], "correct": "C"}, {"question": "Correlation clustering asks to minimize:", "answers": ["The root mean squared error", "The number of disagreements", "The intra-cluster variance", "The running time"], "correct": "B"}, {"question": "If you increase the complexity of your linear regression model, eventually the SSE on the test set will:", "answers": ["Approach zero", "Cancel the training error", "Exceed the training error", "Become negative"], "correct": "C"}, {"question": "Classification accuracy is misleading when:", "answers": ["The label proportions are unbalanced", "The dataset is too small", "The label proprtions are balanced", "The dataset is too large"], "correct": "A"}, {"question": "The worst-case running time of the k-means algorithm on the n points is:", "answers": ["Polynomial in n", "Superpolynomial in n", "Linear in n", "Unbounded in n"], "correct": "B"}, {"question": "In linear regression, the expected squared error s the sum of:", "answers": ["The good the bad and the ugly", "Squared bias and variance and noise", "Underfit and overfit the noise", "Variance and covariance and noise"], "correct": "B"}, {"question": "Your friend proposes an innovative clustering algorithm that enumerates all possible clusterings of the points. This algorithm:", "answers": ["Has exponential complexity", "Has polynomial complexity", "Is efficient but gives poor clustering", "Is efficient and gives good clusterings"], "correct": "A"}, {"question": "A high R^2 on a given dataset means:", "answers": ["A large error on new data", "A large error on that data", "A small error on that data", "A small error on new data"], "correct": "C"}, {"question": "Multicollinearity arises if the features vectors are:", "answers": ["absolutely orthonogal", "linearly dependent", "linearly independent", "positive semidefinite"], "correct": "B"}, {"question": "A logistic regression model learns:", "answers": ["The conditional distribution of predictors", "The conditional distribution of labels", "The marginal distribution of predictors", "The marginal distribution of labels"], "correct": "B"}, {"question": "Consider the LP: min f(x,y) = x + y; x+y >= 2; x, y <= 0. The corresponding polytope is:", "answers": ["Bounded", "empty", "Degenerate", "Unbounded"], "correct": "B"}, {"question": "To measure the efficiency of algorithms we use:", "answers": ["convex analysis", "asymptotic analysis", "squared analysis", "clinical analysis"], "correct": "B"}, {"question": "Everything else being equal, what does suggest a good clustering?", "answers": ["a high p-value", "a low within-cluster sum of squares", "a large number of observations", "a small number of clusters"], "correct": "B"}, {"question": "The set cover problem:", "answers": ["Can be solved in constant time", "is part of linear programming", "is NP-Complete", "is P-Complete"], "correct": "C"}, {"question": "A company must allocate 5M\u20ac so that each department receives a minimum amount. You can use:", "answers": ["Linear regression", "Logistic Regression", "Clustering", "Linear Programming"], "correct": "C"}, {"question": "With hierarchical clustering on n points you can get:", "answers": ["Between 1 and n clusters", "No satisfaction", "Up to 2^n clusters", "At most log(n) clusters"], "correct": "A"}, {"question": "The standard assumption of linear regression is that the noise across the observations:", "answers": ["is fast and furios", "is always bounded", "is Gaussian and correlated", "is Gaussian and independent"], "correct": "D"}, {"question": "The ROC curve is used to measure:", "answers": ["The amount of overfitting and underfitting", "The noise in the training dataset", "The performance of binary classifiers", "The MSE obtained by a linear regression\""], "correct": "C"}, {"question": "Geometrically, each constraint of a linear program corresponds to:", "answers": ["a vector", "A double-space", "a cone", "a half-space"], "correct": "D"}, {"question": "Many well-known clustering problems are:", "answers": ["impossible to solve", "NP-hard", "easy to solve", "infeasible\""], "correct": "B"}, {"question": "A polytope is:", "answers": ["The difference of half-spaces", "the greatest gift of all", "the union of half-spaces", "The intersection of half spaces"], "correct": "D"}, {"question": "Everything else being equal. What does suggest good clustering?", "answers": ["Few clusters", "low within-cluster sum of squares", "high p-value", "large number of points"], "correct": "A"}]